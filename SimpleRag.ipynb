{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67a7d533",
   "metadata": {},
   "source": [
    "### Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3cd89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pydantic-core pydantic\n",
    "%pip install langchain langchain-core langchain-community langchain-ollama langchain-chroma pypdf docx2txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda21e99",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92a82dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abcb7392",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOC_PATH = \"/Users/path\"\n",
    "DB_PATH = \"./vector_db\" \n",
    "MODEL_NAME = \"llama3.2\"\n",
    "EMBEDDING_MODEL = \"nomic-embed-text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f799be4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents(folder_path):\n",
    "    \"\"\"Loads PDF and Word documents from a folder.\"\"\"\n",
    "    documents = []\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "        print(f\"Created folder '{folder_path}'. Please put your documents there and run again.\")\n",
    "        return []\n",
    "\n",
    "    for file in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        if file.endswith(\".pdf\"):\n",
    "            print(f\"Loading PDF: {file}\")\n",
    "            loader = PyPDFLoader(file_path)\n",
    "            documents.extend(loader.load())\n",
    "        elif file.endswith(\".docx\"):\n",
    "            print(f\"Loading Word: {file}\")\n",
    "            loader = Docx2txtLoader(file_path)\n",
    "            documents.extend(loader.load())\n",
    "    return documents\n",
    "\n",
    "def create_vector_db(documents):\n",
    "    \"\"\"Chunks documents and stores them in ChromaDB using Ollama embeddings.\"\"\"\n",
    "    if not documents:\n",
    "        print(\"No documents to process.\")\n",
    "        return None\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    print(f\"Split documents into {len(chunks)} chunks.\")\n",
    "\n",
    "    embeddings = OllamaEmbeddings(model=EMBEDDING_MODEL)\n",
    "\n",
    "    vector_store = Chroma.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=DB_PATH\n",
    "    )\n",
    "    print(\"Vector database created successfully.\")\n",
    "    return vector_store\n",
    "\n",
    "def setup_rag_chain(vector_store):\n",
    "    \"\"\"Sets up the RAG retrieval chain.\"\"\"\n",
    "    llm = ChatOllama(model=MODEL_NAME)\n",
    "\n",
    "    retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    You MUST answer the user's question based STRICTLY and EXCLUSIVELY on the following context.\n",
    "    \n",
    "    CRITICAL INSTRUCTIONS:\n",
    "    1. Use ONLY the information provided in the context below\n",
    "    2. Do NOT use any external knowledge or assumptions\n",
    "    3. If the context does not contain sufficient information to answer the question, you MUST respond with EXACTLY this message:\n",
    "    \n",
    "    \"Thank you for contacting the AI Cybersecurity team. We would be glad to follow up on your inquiry via email. Please provide us with your preferred email address so we can respond accordingly.\"\n",
    "    \n",
    "    4. Do NOT attempt to partially answer or guess\n",
    "    5. Do NOT say \"I don't know\" or variations - use the exact message above\n",
    "    6. Do NOT add any additional commentary beyond the required response\n",
    "    \n",
    "    Context:\n",
    "    {context}\n",
    "    \n",
    "    Question: \n",
    "    {input}\n",
    "    \n",
    "    Answer:\"\"\")\n",
    "\n",
    "    # Create the chain: Retriever -> Combine Docs -> LLM\n",
    "    document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "    retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "    \n",
    "    return retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1255b3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 19 0 (offset 0)\n",
      "Ignoring wrong pointing object 26 0 (offset 0)\n",
      "Ignoring wrong pointing object 31 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 19 0 (offset 0)\n",
      "Ignoring wrong pointing object 26 0 (offset 0)\n",
      "Ignoring wrong pointing object 31 0 (offset 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 19 0 (offset 0)\n",
      "Ignoring wrong pointing object 26 0 (offset 0)\n",
      "Ignoring wrong pointing object 31 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 19 0 (offset 0)\n",
      "Ignoring wrong pointing object 26 0 (offset 0)\n",
      "Ignoring wrong pointing object 31 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PDF: FaQ2.pdf\n",
      "Loading PDF: Faq.pdf\n",
      "Split documents into 9 chunks.\n",
      "Vector database created successfully.\n",
      "Vector database created successfully.\n"
     ]
    }
   ],
   "source": [
    "raw_docs = load_documents(DOC_PATH)\n",
    "vector_db = create_vector_db(raw_docs)\n",
    "rag_chain = setup_rag_chain(vector_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cb563d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Thank you for contacting the AI Cybersecurity team. We would be glad to follow up on your inquiry via email. Please provide us with your preferred email address so we can respond accordingly.\n"
     ]
    }
   ],
   "source": [
    "query = \"How are you implementing RAG with LangChain and Ollama?\"\n",
    "if rag_chain:\n",
    "    response = rag_chain.invoke({\"input\": query})\n",
    "    print(\"Response:\", response.get('answer'))\n",
    "else:\n",
    "    print(\"RAG chain setup failed. Please check the previous steps.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018c2327",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311_torch29",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
